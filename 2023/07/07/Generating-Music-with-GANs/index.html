<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
    <title>
        Generating Music with GANs - RitzzzZ 
    </title>
     
    
<link rel="stylesheet" href="/css/grid.css">

    
<link rel="stylesheet" href="/css/custom.css">

    
<link rel="stylesheet" href="/css/ringo.css">

     
        <link rel="icon" type="image/x-icon" href="/img/favicon.ico " />
     
     
     
        <meta name=" " content="" />
     
        <meta name=" " content="" />
     
 
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>

  <body>
    <header id="header" class="clearfix" onclick="window.open('/', '_self')">
    <div class="site-name">
        <a href="/" id="logo" class="site-title">
            RitzzzZ
        </a>
        <p class="description site-description">
            <span style="padding-top:20px; font-size: 10px">
                An infinite journey
            </span>
        </p>
    </div>
</header>
<div id="sidebar" role="complementary">
    <section class="widget">
        <ul class="menu widget-list">
            
                <li class="menu-item">
                    <a href="/" class="menu-item-link">
                        Home
                    </a>
                </li>
                
                <li class="menu-item">
                    <a href="/about" class="menu-item-link">
                        About
                    </a>
                </li>
                
                <li class="menu-item">
                    <a href="/archives" class="menu-item-link">
                        Archives
                    </a>
                </li>
                
        </ul>
    </section>
    <section class="widget sidebar-foot">
        <ul class="widget-list">
            <li>Theme <a rel="nofollow" target="_blank" href="https://github.com/HeliumOI/hexo-theme-ringo">Ringo</a>
                by <a target="_blank" href="/ "> RitzzzZ  </a></li>
            <li>Proudly powered by  <a rel="nofollow" target="_blank" href="https://hexo.io/">Hexo</a></li>
        </ul>
    </section>
</div>

<div id="helpbar">
    <div class="back-to-top">
        <button id="back2top">↑</button>
        <script>
            back2top.onclick = function() {
                var movement = document.body.scrollTop || document.documentElement.scrollTop;
                scrollBy(0, -movement);
            }
        </script>
    </div>
</div>
      <main class="main">
        <div id="body">
          <div class="container">
            <div class="col-12" id="main" role="main">
    <article class="post post-atpost" itemscope itemtype="http://schema.org/BlogPosting">
        <div class="post-title">
            <h1 class="post-title post-title-atpage" itemprop="name headline">
                <a itemprop="url" href="/2023/07/07/Generating-Music-with-GANs/">
                    Generating Music with GANs
                </a>
            </h1>
        </div>
        <ul class="post-meta post-meta-atpage">
            <li class="post-time">
                2023-07-07
            </li>
            <li>
                <div class="article-category">
                    
                </div>
            </li>
        </ul>
        <div class="post-content" itemprop="articleBody">
            <blockquote>
<p>Notes for tutorial “<a target="_blank" rel="noopener" href="https://salu133445.github.io/ismir2019tutorial/">Generating Music with GANs—An Overview and Case Studies</a>” at ISMIR 2019</p>
</blockquote>
<h2 id="音乐生成研究简述"><a href="#音乐生成研究简述" class="headerlink" title="音乐生成研究简述"></a>音乐生成研究简述</h2><h3 id="音乐制作角度"><a href="#音乐制作角度" class="headerlink" title="音乐制作角度"></a>音乐制作角度</h3><ul>
<li>作曲（songwriting）：旋律，和弦，歌词</li>
<li>编曲（arranging）：器乐，结构</li>
<li>混音（mixing）：音色，平衡</li>
</ul>
<p>音乐人工智能的应用场景：</p>
<ul>
<li>激发音乐人的创作灵感</li>
<li>让每个人都可以制作音乐</li>
<li>为视频或游戏生产版权自由的音乐</li>
<li>音乐教育（比如自动伴奏）</li>
</ul>
<p>相关公司：参考<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/556608208">这篇文章</a></p>
<h3 id="深度学习的角度"><a href="#深度学习的角度" class="headerlink" title="深度学习的角度"></a>深度学习的角度</h3><ul>
<li>输入表示</li>
<li>模型<ul>
<li>基于规则的方法</li>
<li>基于连接的方法</li>
<li>基于机器学习的方法：VAE，GAN</li>
</ul>
</li>
<li>输出表示</li>
</ul>
<p>输入/输出表示</p>
<ul>
<li>离散的符号输出：<strong>钢琴卷</strong>（类似图像），MIDI（类似文本），乐谱（混合）</li>
<li>连续的音频输出：<strong>频谱</strong>（类似图像），信号波</li>
</ul>
<p>这些表示方法的介绍可以参考<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/166660784">这里</a>。</p>
<h3 id="问题分类"><a href="#问题分类" class="headerlink" title="问题分类"></a>问题分类</h3><ul>
<li>从头开始生成：由某个输入得到旋律，钢琴卷或音频</li>
<li>条件生成：由旋律得到钢琴卷（伴奏），由钢琴卷得到音频（合成），由钢琴卷A得到钢琴卷B（重新编曲），由音频A得到音频B</li>
</ul>
<p>一些重要的工作：</p>
<ol>
<li>Symbolic melody generation: MidiNet [1], SSMGAN [2]</li>
<li>Arrangement generation: MuseGAN [3], BinaryMuseGAN [4], LeadSheetGAN [5]</li>
<li>Style transfer: CycleGAN [6], TimbreTron [7], Play-as-you-like [8], CycleBEGAN [9]</li>
<li>Audio generation: WaveGAN [10], GANSynth [11]</li>
</ol>
<blockquote>
<p>[1] “MidiNet: A convolutional GAN for symbolic-domain music generation,” ISMIR 2017<br>[2] “Modeling self-repetition in music generation using structured adversaries,” ML4MD 2019<br>[3] “MuseGAN: Multi-track sequential GANs for symbolic music generation and accompaniment,” AAAI 2018<br>[4] “Convolutional GANs with binary neurons for polyphonic music generation,” ISMIR 2018<br>[5] “Lead sheet generation and arrangement by conditional GAN,” ISMIR-LBD 2018<br>[6] “Symbolic music genre transfer with CycleGAN,” ICTAI 2018<br>[7] “TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) pipeline for musical timbre transfer,” ICLR 2019<br>[8] “Play as You Like: Timbre-enhanced multi-modal music style transfer,” AAAI 2019<br>[9] “Singing style transfer using cycle-consistent boundary equilibrium GANs,” ICML workshop 2018<br>[10] “Adversarial audio synthesis,” ICLR 2019<br>[11] “GANSynth: Adversarial neural audio synthesis,” ICLR 2019  </p>
</blockquote>
<h2 id="GANs简介"><a href="#GANs简介" class="headerlink" title="GANs简介"></a>GANs简介</h2><p>训练生成模型的损失函数定义为对数损失函数。流向判别器的损失是将真实样本判断为假和将假样本判断为真。流向生成器的损失是被判别器判断为假的样本数，因为我们希望生成的样本尽可能让判别器认为是真的。</p>
<p><img src="GAN.png" alt="GAN"></p>
<p>不规范的GANs存在一些问题。判别器为生成器提供的梯度指出了改进方向。判别比生成简单，而判别器倾向于提供大梯度（在图像中体现为明显、急剧的颜色变化），导致生成器的训练不够稳定。常见的失败情况有模式损坏（mode collapse，被判断为假的区域中有一块缺失判断），模式缺失（missing modes，被判断为真的区域中有一块缺失判断）。</p>
<p>规范化的GANs：为生成器提供更光滑的引导，减轻mode collapse和missing modes问题。</p>
<p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/salu133445/ismir2019tutorial/blob/main/gan.ipynb#scrollTo=716vG6H-ldA7">demo: GAN for images（Google Colab)</a></p>
<h3 id="GANs-vs-VAEs"><a href="#GANs-vs-VAEs" class="headerlink" title="GANs vs VAEs"></a>GANs vs VAEs</h3><p><img src="GANvsVAE.png" alt="GANs vs VAEs"></p>
<h3 id="SOTA方法"><a href="#SOTA方法" class="headerlink" title="SOTA方法"></a>SOTA方法</h3><p>可以在<a target="_blank" rel="noopener" href="https://github.com/hindupuravinash/the-gan-zoo">这个网站</a>查看各种各样的GANs模型。</p>
<p><strong>BigGANs</strong>：在潜空间上插值。<a target="_blank" rel="noopener" href="https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb">demo (Google Colab)</a></p>
<p><strong>Conditional GAN (CGAN)</strong>：对生成器和判别器都加上一个条件输入。</p>
<p><img src="cgan.png" alt="CGAN"></p>
<p><strong>pix2pix</strong>：用逐像素点的损失来监督。</p>
<p><img src="pix2pix.png" alt="pix2pix"></p>
<p><strong>Cycle-consistent GAN (CycleGAN)</strong>：用循环一致的损失来监督，用于image-to-image translation（比如风格迁移）。</p>
<p><img src="cyclegan.png" alt="cyclegan"></p>
<p>pix2pix和CycleGAN的损失计算方式如下图：</p>
<p><img src="cmp.png" alt="cmp"></p>
<h2 id="基于GANs的音乐生成方法举例"><a href="#基于GANs的音乐生成方法举例" class="headerlink" title="基于GANs的音乐生成方法举例"></a>基于GANs的音乐生成方法举例</h2><p>包含了很多数据集的Github仓库：<a target="_blank" rel="noopener" href="https://github.com/wayne391/symbolic-music-datasets">symbolic datasets collection</a></p>
<h3 id="符号旋律生成（Symbolic-melody-generation）"><a href="#符号旋律生成（Symbolic-melody-generation）" class="headerlink" title="符号旋律生成（Symbolic melody generation）"></a>符号旋律生成（Symbolic melody generation）</h3><p><strong>MidiNet</strong>：根据我们对音乐的理解来设计CNN核的大小。</p>
<p><strong>SSMGAN</strong>：用GAN生成一个自相似矩阵（SSM）表示音乐中的自我重复，改进全局音乐结构；然后用LSTM生成旋律。</p>
<p><img src="ssmgan.png" alt="ssmgan"></p>
<h3 id="编曲生成（Arrangement-generation）"><a href="#编曲生成（Arrangement-generation）" class="headerlink" title="编曲生成（Arrangement generation）"></a>编曲生成（Arrangement generation）</h3><p>挑战：</p>
<ul>
<li>随时间的变化：动态，情绪，紧张度等</li>
<li>结构：长结构很难生成</li>
<li>器乐：多个音轨，要考虑乐器的作用</li>
</ul>
<p>在真实世界的音乐中，这些元素以非常复杂的方式组织起来。</p>
<p><strong>钢琴卷</strong><br><img src="pianoroll.png" alt="pianoroll"></p>
<p>优点：</p>
<ol>
<li>非常好的符号化——用节拍来量化</li>
<li>很容易观察到重复、结构</li>
<li>不需要序列化复调创作</li>
</ol>
<p>缺点：</p>
<ol>
<li>存储效率低——大部分位置填充0，矩阵稀疏</li>
<li>抛开了音符的概念</li>
<li>很难处理演出级别的信息，除非使用高分辨率</li>
</ol>
<p><strong>MuseGAN</strong>：用不同类型的潜变量增强可控性。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">time dependent</th>
<th style="text-align:center">time independent</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">track dependent</td>
<td style="text-align:center">melody</td>
<td style="text-align:center">groove</td>
</tr>
<tr>
<td style="text-align:center">track independent</td>
<td style="text-align:center">chords</td>
<td style="text-align:center">style</td>
</tr>
</tbody>
</table>
</div>
<p><img src="musegan.png" alt="musegan"></p>
<p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/salu133445/ismir2019tutorial/blob/main/musegan.ipynb">demo: GAN for pianorolls (Google Colab)</a></p>
<p><strong>BinaryMuseGAN</strong>：简单的二值化方法容易导致音符过于碎片化。BinaryMuseGAN的生成器输出层使用二值化神经元，用straight-through estimator估计梯度（使用不可微的操作符）。</p>
<p><strong>LeadSheetGAN</strong>：分为三步</p>
<ol>
<li>用非条件GAN生成时域，小节（称为lead sheet）</li>
<li>将上一步的输出组合成feature</li>
<li>将feature作为条件，和潜变量一起输入一个条件GAN，生成每个小节的编曲</li>
</ol>
<p><img src="leadsheetgan.png" alt="leadsheetgan"></p>
<h3 id="风格迁移（Style-transfer）"><a href="#风格迁移（Style-transfer）" class="headerlink" title="风格迁移（Style transfer）"></a>风格迁移（Style transfer）</h3><p>分类：</p>
<ol>
<li>作曲风格迁移（保留内容，改变风格）：可以用标准CycleGAN，输入输出使用单轨钢琴卷。</li>
<li>演奏风格迁移：这方面的工作基本不使用深度学习）</li>
<li>音色风格迁移</li>
</ol>
<p><strong>Sony CSL Flow Machine</strong>：对音乐风格（genre）进行风格迁移。<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=buXqNqBFd6E">demo</a></p>
<p><strong>TimbreTron</strong>：通过三个步骤对音色进行风格迁移。</p>
<ol>
<li>计算<a target="_blank" rel="noopener" href="https://iphysresearch.github.io/blog/post/signal_processing/cqt/">CQT（Constant Q Transform)</a> 频谱图并将其对数幅度值视为图像（丢弃相位信息）</li>
<li>使用改进的CycleGAN在对数CQT域中执行音色转换</li>
<li>使用条件的WaveNet生成器将生成的log-CQT转换为音频（这必须推断出丢失的相位信息）</li>
</ol>
<p><img src="timbretron.png" alt="timbretron"></p>
<p>TimbreTron可以在某些乐器对上成功进行音乐音色转换，同时保留相同的音乐内容（例如，节奏，响度，音调）。CQT表示法是TimbreTron中的关键组成部分，与STFT对应部分相比，它能实现低频的高频率分辨率和高频的高时间分辨率，从而得到更好的转换音质。</p>
<p><strong>CycleGAN vs MUNIT</strong>：MUNIT (Multimodal unsupervised Image-to-Image Translation) 在CycleGAN基础上加入encoders/decoders，让内容和风格解耦。比起只能一次在两个域上进行转换的CycleGAN，MUNIT可以同时在多个域上进行转换。</p>
<p><strong>Play-as-you-like</strong>：使用MUNIT进行无监督的音色转换，这一方法的核心是分离出domain invariant（音乐的内容）和domain specific（音乐的音色）的特征，然后通过不同的domain的部分进行转换生成。对每个domain有一个编码器$E$将原始音乐编码为内容$c$和风格$s$，一个生成器$G$根据输入的$c$和$s$生成对应的音乐，还有就是一个域鉴别器$D$，训练时使用Relativistic average GAN（RaGAN）的损失。该方法通过自身的重建、跨域生成鉴别损失、生成后再编码的编码一致性损失学习跨域的转换。由于这个方法中没有使用Cycle Consistency，所以基于上述损失不能保证转换后保留原始的音乐结构。所以该方法设计了一个Intrinsic Consistency Loss，约束转换前后的音乐的一些自相关的频域特征不变（mel-frequency cepstral coefficients (MFCC), spectral difference, and spectral envelope），从而约束音乐的自身结构不变。</p>
<p><strong>CycleBEGAN</strong>：用BEGAN模型替换GAN，使用skip connections &amp; recurrent layer。skip connections保持了歌声的清晰、自然，recurrent layers提高了各方面，尤其是音高准确性。在男女歌声之间进行transfer。</p>
<h3 id="音频生成（Audio-generation）"><a href="#音频生成（Audio-generation）" class="headerlink" title="音频生成（Audio generation）"></a>音频生成（Audio generation）</h3><p><strong>SpecGAN</strong>：模型基于DCGAN。将2D卷积平铺成1D（例如，5*5 2D conv变成25 1D conv），步长也相应进行增加（例如，2*2变成步长为4）。DCGAN生成$64\times 64$的图像，SpecGAN再增加一层，生成有16,384个点，即16kHz的频谱。</p>
<p><strong>PGGAN</strong>：每个step不断增加latent的分辨率，在不同分辨率下训练generator和discriminator。</p>
<p><strong>GANSynth</strong>：模型基于PGGAN（progressive growing GAN），从低到高逐渐增加分辨率，生成信号波。</p>
<p><img src="gansynth.png" alt="gansynth"></p>
<p>训练过程中，在两种不同分辨率的输出之间以权重$\alpha$进行插值，$\alpha$线性地从0增长到1。最终输出的是mel-spectrogram + instantaneous freq (IF)。用 IF 可以推导出相位，然后用inverse STFT可以得到波形。</p>
<p><img src="gansynth2.png" alt="gansynth2"></p>
<h2 id="目前局限-amp-未来研究方向"><a href="#目前局限-amp-未来研究方向" class="headerlink" title="目前局限&amp;未来研究方向"></a>目前局限&amp;未来研究方向</h2><h3 id="GANs的局限性"><a href="#GANs的局限性" class="headerlink" title="GANs的局限性"></a>GANs的局限性</h3><ul>
<li>训练有些困难</li>
<li>只能学到一个方向的映射，而不是双向的</li>
<li>解释性较差</li>
<li>不太清楚GANs如何建模文本类的数据或者乐谱</li>
<li>不清楚GANs（以及所有其他的作曲模型）如何生成新的音乐类型</li>
</ul>
<p>其他的生成模型：VAEs, flow-based models, autoregressive models, attention mechanisms, restricted Boltzmann machines, hidden Markov models…</p>
<h3 id="未来研究方向"><a href="#未来研究方向" class="headerlink" title="未来研究方向"></a>未来研究方向</h3><ul>
<li>更好的适用于音乐数据的网络结构，多样性，可解释性，可控性</li>
<li>数据集和评估标准</li>
<li>跨模态生成</li>
<li>交互</li>
<li>表演风格迁移</li>
<li>在乐句级别上进行生成，而不是音符级别</li>
<li>多声部，无歌词，EDM的生成，…</li>
</ul>

             
        </div>
        
    </article>
    <div class="post-near">
    <div class="post-near-child post-near-child-left "> 
        
            <a href="/2023/07/06/PyTorch/">PyTorch补漏 &laquo; </a>
        
        <br /> Prev  &laquo;
    </div>
    <div class="post-near-child post-near-child-right">
        
            <a href="/2023/07/11/Audiovisual-Music-Performance-Analysis/"> &raquo; Audiovisual Music Performance Analysis</a>
        
        <br /> &raquo; Next 
    </div>
</div>
</div>
             
<div id="comments">
     
</div>
 
            <footer id="footer" role="contentinfo">
    
        &copy; 2022 - 2025
        <br />
    
    
    <br />
    
    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        <span id="busuanzi_value_site_pv">......</span> visits ·
        <span id="busuanzi_value_site_uv">......</span> visitors 
    
</footer>
          </div>
        </div>
      </main>
      <!-- highlight support -->

    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.1.0/build/styles/default.min.css">


<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.1.0/build/highlight.min.js"></script>
 
<script>
        hljs.initHighlightingOnLoad();
</script>
 
<!-- prettify support -->

    
<link rel="stylesheet" href="/prettify/prettify.css">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/color-themes-for-google-code-prettify@2.0.4/dist/themes/tomorrow.min.css">


<script src="/prettify/prettify.js"></script>


<script>
    let prettifyel = document.querySelectorAll('pre');
    for (let i = 0; i < (prettifyel || []).length; i += 1) {
        prettifyel[i].classList.add('prettyprint');
        prettifyel[i].classList.add('linenums');
    }
    PR.prettyPrint();
</script>
 
<!-- mathjax support -->

    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>


<!-- fancybox support -->
 
<!-- viewerjs support -->

    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/viewerjs@1.10.0/dist/viewer.min.css">


<script src="https://cdn.jsdelivr.net/npm/viewerjs@1.10.0/dist/viewer.min.js"></script>

<script type="text/javascript">
    Viewer.setDefaults({
        zoomRatio: [0.5],
        show: function () {
            this.viewer.zoomTo(1);
        },
    });
    
    var imageList = document.querySelector('.post-content').getElementsByTagName('img');
    
    var imageArray = new Array();
    Array.prototype.forEach.call(imageList, element => {
        if (element.alt != "no-view" && element.className != "no-view") {
            imageArray.push(element);
        }
    });
    
    Array.prototype.forEach.call(imageArray, element => {
        var viewer1 = new Viewer(element);
        viewer1.images = imageArray;
        viewer1.length = imageArray.length;
    });
</script>
 
<!-- google analytics support -->



 
 

<!-- lazyload support -->

    
<script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.4.0/dist/lazyload.min.js"></script>

<script>
    new LazyLoad({
        elements_selector: '.post-content img'
    });
</script>
 
  </body>

</html>